{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Check_Pretrained_Model_on SQUAD2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNF0kKY4Yg0RfKKdyWiONTt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhadreshpsavani/100-Days-of-DS-and-Algorithm/blob/master/Check_Pretrained_Model_on_SQUAD2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3F-u_bdHV6K",
        "outputId": "02ca94b9-8ea0-43af-8ef1-6d5241f76b35"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\r\n",
        "%cd transformers\r\n",
        "!pip install .\r\n",
        "!pip install -r ./examples/question-answering/requirements.txt\r\n",
        "%cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 66890 (delta 9), reused 15 (delta 5), pack-reused 66867\u001b[K\n",
            "Receiving objects: 100% (66890/66890), 49.80 MiB | 29.98 MiB/s, done.\n",
            "Resolving deltas: 100% (47516/47516), done.\n",
            "/content/transformers\n",
            "Processing /content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 18.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.4.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.4.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.4.0.dev0) (2.4.7)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.4.0.dev0-cp37-none-any.whl size=1969178 sha256=1f20403c280a69c8b348075154b55e84e37160fca59e9eb77a110bc02bbc9a8c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l38b7yqd/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=96cd67164f0773e4526d94d0fd4f447b270327a49595d5d434073a3ec1619076\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.0.dev0\n",
            "Collecting datasets>=1.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/73/742d17d8a9a1c639132affccc9250f0743e484cbf263ede6ddcbe34ef212/datasets-1.4.1-py3-none-any.whl (186kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 17.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (0.70.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (1.19.5)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 38.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (2.23.0)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/27/1c0b37c53a7852f1c190ba5039404d27b3ae96a55f48203a74259f8213c9/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 49.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (3.0.0)\n",
            "Collecting huggingface-hub==0.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/93/7cb0755c62c36cdadc70c79a95681df685b52cbaf76c724facb6ecac3272/huggingface_hub-0.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.2->datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.2.1->-r ./examples/question-answering/requirements.txt (line 1)) (1.15.0)\n",
            "Installing collected packages: fsspec, xxhash, huggingface-hub, datasets\n",
            "Successfully installed datasets-1.4.1 fsspec-0.8.7 huggingface-hub-0.0.2 xxhash-2.0.0\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX2E4B74JFcI",
        "outputId": "4aac95a6-782a-4da1-937f-7e2d1620b78a"
      },
      "source": [
        "!pip install -q sentencepiece"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 24.1MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 29.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 33.4MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 36.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 36.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 37.1MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 23.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 21.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 23.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 22.0MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 22.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 22.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 22.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 22.0MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 22.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 22.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 22.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6XNWBPpIVHc",
        "outputId": "dedcae43-4977-4c28-a8c2-4da4ae5eddfe"
      },
      "source": [
        "!python ./transformers/examples/question-answering/run_qa.py \\\r\n",
        "--model_name_or_path ktrapeznikov/albert-xlarge-v2-squad-v2 \\\r\n",
        "--dataset_name squad_v2 \\\r\n",
        "--do_eval \\\r\n",
        "--max_val_sample 10 \\\r\n",
        "--per_device_train_batch_size 12 \\\r\n",
        "--learning_rate 3e-5 \\\r\n",
        "--num_train_epochs 2 \\\r\n",
        "--max_seq_length 384 \\\r\n",
        "--doc_stride 128 \\\r\n",
        "--output_dir /tmp/debug_squad/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-15 12:19:51.875270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "03/15/2021 12:19:53 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "03/15/2021 12:19:53 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=/tmp/debug_squad/, overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=12, per_device_eval_batch_size=8, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/Mar15_12-19-53_af7fd8fd3ffc, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=/tmp/debug_squad/, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=1)\n",
            "Downloading: 5.07kB [00:00, 6.25MB/s]       \n",
            "Downloading: 2.23kB [00:00, 2.87MB/s]     \n",
            "Downloading and preparing dataset squad_v2/squad_v2 (download: 44.34 MiB, generated: 122.57 MiB, post-processed: Unknown size, total: 166.91 MiB) to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/9cac55034b086140f0649ecb5c604d09d7da2f2f5b73a90caa2e2bcc1f5cac09...\n",
            "Downloading: 42.1MB [00:00, 103MB/s]\n",
            "Downloading: 4.37MB [00:00, 110MB/s]       \n",
            "Dataset squad_v2 downloaded and prepared to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/9cac55034b086140f0649ecb5c604d09d7da2f2f5b73a90caa2e2bcc1f5cac09. Subsequent calls will reuse this data.\n",
            "[INFO|file_utils.py:1382] 2021-03-15 12:20:03,450 >> https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpxg7_stsw\n",
            "Downloading: 100% 717/717 [00:00<00:00, 881kB/s]\n",
            "[INFO|file_utils.py:1386] 2021-03-15 12:20:03,468 >> storing https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/63d792c1dbb44e8689d1e7a2c0ae7fc7eaa5d787021a85ebfba99d7e7fd4a0c1.e2cacd8449f3336b177473e9974534c5d5c11e7a6c3602c7f8b160b52b703710\n",
            "[INFO|file_utils.py:1389] 2021-03-15 12:20:03,468 >> creating metadata file for /root/.cache/huggingface/transformers/63d792c1dbb44e8689d1e7a2c0ae7fc7eaa5d787021a85ebfba99d7e7fd4a0c1.e2cacd8449f3336b177473e9974534c5d5c11e7a6c3602c7f8b160b52b703710\n",
            "[INFO|configuration_utils.py:463] 2021-03-15 12:20:03,468 >> loading configuration file https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/63d792c1dbb44e8689d1e7a2c0ae7fc7eaa5d787021a85ebfba99d7e7fd4a0c1.e2cacd8449f3336b177473e9974534c5d5c11e7a6c3602c7f8b160b52b703710\n",
            "[INFO|configuration_utils.py:499] 2021-03-15 12:20:03,469 >> Model config AlbertConfig {\n",
            "  \"architectures\": [\n",
            "    \"AlbertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.4.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:463] 2021-03-15 12:20:03,485 >> loading configuration file https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/63d792c1dbb44e8689d1e7a2c0ae7fc7eaa5d787021a85ebfba99d7e7fd4a0c1.e2cacd8449f3336b177473e9974534c5d5c11e7a6c3602c7f8b160b52b703710\n",
            "[INFO|configuration_utils.py:499] 2021-03-15 12:20:03,486 >> Model config AlbertConfig {\n",
            "  \"architectures\": [\n",
            "    \"AlbertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.4.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1382] 2021-03-15 12:20:03,510 >> https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7rysuiug\n",
            "Downloading: 100% 760k/760k [00:00<00:00, 21.1MB/s]\n",
            "[INFO|file_utils.py:1386] 2021-03-15 12:20:03,570 >> storing https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/6276f297211781cf72c7b6c6c5b40ce82b3bd0f41078b46284be1243a02d8e0c.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d\n",
            "[INFO|file_utils.py:1389] 2021-03-15 12:20:03,570 >> creating metadata file for /root/.cache/huggingface/transformers/6276f297211781cf72c7b6c6c5b40ce82b3bd0f41078b46284be1243a02d8e0c.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d\n",
            "[INFO|file_utils.py:1382] 2021-03-15 12:20:03,604 >> https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/added_tokens.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpngy9yoih\n",
            "Downloading: 100% 2.00/2.00 [00:00<00:00, 3.18kB/s]\n",
            "[INFO|file_utils.py:1386] 2021-03-15 12:20:03,622 >> storing https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/added_tokens.json in cache at /root/.cache/huggingface/transformers/ba6c93b2c4622b97c1822a73e4ca016a60e7de0950186c61a7343b414f435f0b.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|file_utils.py:1389] 2021-03-15 12:20:03,622 >> creating metadata file for /root/.cache/huggingface/transformers/ba6c93b2c4622b97c1822a73e4ca016a60e7de0950186c61a7343b414f435f0b.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|file_utils.py:1382] 2021-03-15 12:20:03,638 >> https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpl64mylr8\n",
            "Downloading: 100% 156/156 [00:00<00:00, 240kB/s]\n",
            "[INFO|file_utils.py:1386] 2021-03-15 12:20:03,654 >> storing https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/0865fb818019b2e454970b3c0ebd6ad9c5ef1eac68c6188d7703bd1f13f02ae7.623993453f3f6b9f6ad831899812f482e5cde100e664124feb3a6446d69a26bf\n",
            "[INFO|file_utils.py:1389] 2021-03-15 12:20:03,654 >> creating metadata file for /root/.cache/huggingface/transformers/0865fb818019b2e454970b3c0ebd6ad9c5ef1eac68c6188d7703bd1f13f02ae7.623993453f3f6b9f6ad831899812f482e5cde100e664124feb3a6446d69a26bf\n",
            "[INFO|file_utils.py:1382] 2021-03-15 12:20:03,671 >> https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpxf1aljau\n",
            "Downloading: 100% 58.0/58.0 [00:00<00:00, 84.2kB/s]\n",
            "[INFO|file_utils.py:1386] 2021-03-15 12:20:03,688 >> storing https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/feef3909ed005e95d21b0c3824093015275138c70d80e78c2d75d03f8fbc0ebd.11d9edb6b1301b5af13d33c1585ff45ff84dd55cc6915c2872f856d1ee2dc409\n",
            "[INFO|file_utils.py:1389] 2021-03-15 12:20:03,688 >> creating metadata file for /root/.cache/huggingface/transformers/feef3909ed005e95d21b0c3824093015275138c70d80e78c2d75d03f8fbc0ebd.11d9edb6b1301b5af13d33c1585ff45ff84dd55cc6915c2872f856d1ee2dc409\n",
            "[INFO|tokenization_utils_base.py:1702] 2021-03-15 12:20:03,689 >> loading file https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/6276f297211781cf72c7b6c6c5b40ce82b3bd0f41078b46284be1243a02d8e0c.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d\n",
            "[INFO|tokenization_utils_base.py:1702] 2021-03-15 12:20:03,689 >> loading file https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/tokenizer.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1702] 2021-03-15 12:20:03,689 >> loading file https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/ba6c93b2c4622b97c1822a73e4ca016a60e7de0950186c61a7343b414f435f0b.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|tokenization_utils_base.py:1702] 2021-03-15 12:20:03,689 >> loading file https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/0865fb818019b2e454970b3c0ebd6ad9c5ef1eac68c6188d7703bd1f13f02ae7.623993453f3f6b9f6ad831899812f482e5cde100e664124feb3a6446d69a26bf\n",
            "[INFO|tokenization_utils_base.py:1702] 2021-03-15 12:20:03,689 >> loading file https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/feef3909ed005e95d21b0c3824093015275138c70d80e78c2d75d03f8fbc0ebd.11d9edb6b1301b5af13d33c1585ff45ff84dd55cc6915c2872f856d1ee2dc409\n",
            "[INFO|file_utils.py:1382] 2021-03-15 12:20:03,828 >> https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpt44tvx85\n",
            "Downloading: 100% 235M/235M [00:05<00:00, 43.2MB/s]\n",
            "[INFO|file_utils.py:1386] 2021-03-15 12:20:09,571 >> storing https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/8d16ceb92c5e32ffc26f0d5a6e0681bc1808e5b3f9491d07a97a05e8ac320365.c61293af3110d8892035c62624a45f32947d2dbea7e43dd8c2683ce06b9b6648\n",
            "[INFO|file_utils.py:1389] 2021-03-15 12:20:09,572 >> creating metadata file for /root/.cache/huggingface/transformers/8d16ceb92c5e32ffc26f0d5a6e0681bc1808e5b3f9491d07a97a05e8ac320365.c61293af3110d8892035c62624a45f32947d2dbea7e43dd8c2683ce06b9b6648\n",
            "[INFO|modeling_utils.py:1051] 2021-03-15 12:20:09,572 >> loading weights file https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8d16ceb92c5e32ffc26f0d5a6e0681bc1808e5b3f9491d07a97a05e8ac320365.c61293af3110d8892035c62624a45f32947d2dbea7e43dd8c2683ce06b9b6648\n",
            "[INFO|modeling_utils.py:1167] 2021-03-15 12:20:11,176 >> All model checkpoint weights were used when initializing AlbertForQuestionAnswering.\n",
            "\n",
            "[INFO|modeling_utils.py:1176] 2021-03-15 12:20:11,176 >> All the weights of AlbertForQuestionAnswering were initialized from the model checkpoint at ktrapeznikov/albert-xlarge-v2-squad-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertForQuestionAnswering for predictions without further training.\n",
            "100% 1/1 [00:00<00:00, 53.12ba/s]\n",
            "Downloading: 4.51kB [00:00, 5.19MB/s]       \n",
            "Downloading: 3.35kB [00:00, 4.33MB/s]       \n",
            "[INFO|trainer.py:482] 2021-03-15 12:20:22,577 >> The following columns in the evaluation set  don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
            "03/15/2021 12:20:22 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:482] 2021-03-15 12:20:22,678 >> The following columns in the evaluation set  don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
            "[INFO|trainer.py:1772] 2021-03-15 12:20:22,679 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:1773] 2021-03-15 12:20:22,679 >>   Num examples = 10\n",
            "[INFO|trainer.py:1774] 2021-03-15 12:20:22,679 >>   Batch size = 8\n",
            "100% 2/2 [00:02<00:00,  1.14s/it]03/15/2021 12:20:25 - INFO - utils_qa -   Post-processing 11873 example predictions split into 10 features.\n",
            "\n",
            "  0% 0/11873 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 948/11873 [00:00<00:01, 9475.63it/s]\u001b[A\n",
            " 17% 2059/11873 [00:00<00:00, 9912.39it/s]\u001b[A\n",
            " 26% 3139/11873 [00:00<00:00, 10162.72it/s]\u001b[A\n",
            " 36% 4303/11873 [00:00<00:00, 10564.13it/s]\u001b[A\n",
            " 46% 5432/11873 [00:00<00:00, 10770.72it/s]\u001b[A\n",
            " 55% 6573/11873 [00:00<00:00, 10954.68it/s]\u001b[A\n",
            " 65% 7718/11873 [00:00<00:00, 11097.81it/s]\u001b[A\n",
            " 75% 8913/11873 [00:00<00:00, 11339.62it/s]\u001b[A\n",
            " 84% 10013/11873 [00:00<00:00, 11234.35it/s]\u001b[A\n",
            "100% 11873/11873 [00:01<00:00, 11142.80it/s]\n",
            "03/15/2021 12:20:26 - INFO - utils_qa -   Saving predictions to /tmp/debug_squad/predictions.json.\n",
            "03/15/2021 12:20:26 - INFO - utils_qa -   Saving nbest_preds to /tmp/debug_squad/nbest_predictions.json.\n",
            "Traceback (most recent call last):\n",
            "  File \"./transformers/examples/question-answering/run_qa.py\", line 546, in <module>\n",
            "    main()\n",
            "  File \"./transformers/examples/question-answering/run_qa.py\", line 531, in main\n",
            "    metrics = trainer.evaluate()\n",
            "  File \"/content/transformers/examples/question-answering/trainer_qa.py\", line 63, in evaluate\n",
            "    metrics = self.compute_metrics(eval_preds)\n",
            "  File \"./transformers/examples/question-answering/run_qa.py\", line 492, in compute_metrics\n",
            "    return metric.compute(predictions=p.predictions, references=p.label_ids)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/datasets/metric.py\", line 403, in compute\n",
            "    output = self._compute(predictions=predictions, references=references, **kwargs)\n",
            "  File \"/root/.cache/huggingface/modules/datasets_modules/metrics/squad/c0855591f1a2c2af8b7949e3146b9c86a6b7f536b4154019b03472639d310181/squad.py\", line 109, in _compute\n",
            "    score = evaluate(dataset=dataset, predictions=pred_dict)\n",
            "  File \"/root/.cache/huggingface/modules/datasets_modules/metrics/squad/c0855591f1a2c2af8b7949e3146b9c86a6b7f536b4154019b03472639d310181/evaluate.py\", line 68, in evaluate\n",
            "    exact_match += metric_max_over_ground_truths(exact_match_score, prediction, ground_truths)\n",
            "  File \"/root/.cache/huggingface/modules/datasets_modules/metrics/squad/c0855591f1a2c2af8b7949e3146b9c86a6b7f536b4154019b03472639d310181/evaluate.py\", line 53, in metric_max_over_ground_truths\n",
            "    return max(scores_for_ground_truths)\n",
            "ValueError: max() arg is an empty sequence\n",
            "100% 2/2 [00:05<00:00,  2.82s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dl-8ryNI3T2"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}